import sys
import subprocess
import pandas as pd
from Bio.Seq import Seq
from Bio import SeqIO
from openpyxl import load_workbook, Workbook


def makedb ():
    command = [
    "makeblastdb",
    "-in", "blastdb/flanking_regions.fasta",
    "-dbtype", "nucl",
    "-out", "blastdb/flanking_regions"
    ]
    
    subprocess.run(command, check=True, stderr=subprocess.DEVNULL)

def blast (library, num_regions):
    print (f"blasting {library} against amplicons")

    blast_command = [
    "blastn",
    "-query", "files/" + library + "_assembled.fasta",
    "-db", "blastdb/flanking_regions",
    "-out", "files/" + library + "_vs_flanking_regions.txt",
    "-outfmt", "6",
    "-max_target_seqs", str(num_regions*2),
    "-max_hsps", "1",
    "-task", "blastn-short" # this arguement is critical for the search to successfully identify the correct alignments. I think it adjusts the gap penalties and scoring matricies to values that are optimized for searches with small sequences.
    ]
    
    subprocess.run(blast_command, check=True, stderr=subprocess.DEVNULL)

def get_variable (first_hit, second_hit, seq, orientation):
        variable = ""
        status = ""

        if orientation == "forward":
            start = int(second_hit [7])
            end = int(first_hit [6])-1
            
            if (start<end) & ((end-start)%3==0): # checks that the region is divisible by 3
                variable = str(seq[start:end].translate())
            else:
                status = "coords_bad"
            
        if orientation == "reverse":
            start = int(second_hit [6])-1
            end = int(first_hit [7])
            
            if (end<start) & ((end-start)%3==0): # checks that the region is divisible by 3
                variable = str(seq[end:start].reverse_complement().translate())
            else:
                status = "coords_bad"   
    
        correct_length_part = second_hit[1].split('-')[1].split('_')[0]  # Extracts length

        # Check if it's a list of acceptable lengths
        if ',' in correct_length_part:
            acceptable_lengths = list(map(int, correct_length_part.split(',')))  # Convert to a list of integers
            if len(variable) not in acceptable_lengths:
                variable = ""
                status = "coords_bad"
        else:
            correct_length = int(correct_length_part)
            if not(len(variable) == correct_length):
                variable = ""
                status = "coords_bad"

        return variable, status

def write_to_excel(file_name, row_data):
    try:
        # Try to load the workbook if it exists
        workbook = load_workbook(file_name)
        sheet = workbook.active
    except FileNotFoundError:
        # If the file doesn't exist, create a new workbook
        workbook = Workbook()
        sheet = workbook.active
        # Add variables (if desired)
        sheet.append(["Fragment Length", "Good Hits", "Wrong Num Hits", "Coords Bad", "Good Hits %", "Wrong Num Hits %", "Coords Bad %"])

    # Append the new row
    sheet.append(row_data)

    # Save the workbook
    workbook.save(file_name)



library = sys.argv[1]
num_regions = int(sys.argv[2])

fasta_file = f"files/{library}_assembled.fasta" # fasta file of reads
blast_file = f"files/{library}_vs_flanking_regions.txt" # blast output (generated by this code)
db_file = "blastdb/flanking_regions.fasta"
good_file = f"files/{library}.xlsx" # reads with variable regions successfully extracted
summary_file = "extraction_summary.xlsx" # summary of extraction success



makedb ()
blast (library, num_regions)



# read blast alignment summaries into dictionary
alignment_dict = {}
with open(blast_file, 'r') as file:
    for line in file:
        parts = line.strip().split("\t")
        read_id = parts[0]
        if read_id not in alignment_dict:
            alignment_dict[read_id] = []
        alignment_dict[read_id].append(parts)




# get the names of the variable regions from the blast database
variables = []
with open(db_file, "r") as file:
    for line in file:
        line = line.strip()
        if line.startswith(">"):  # Indicates a header line in FASTA
            # Extract the prefix before the first underscore
            prefix = line.split("_")[0][1:]
            if prefix not in variables:
                variables.append(prefix)



# extract the variable regions
rows = [] # this becomes the output spreadsheet
wrong_num_hits = 0
coords_bad = 0
good = 0

for record in SeqIO.parse(fasta_file, "fasta"):
    seq_id = record.id  # Extract the sequence ID from the FASTA file
    seq = record.seq # extract the sequence
    
    hits = alignment_dict.get(seq_id, []) # get all of the blast hits for the read
    if len(hits) == num_regions*2:
        double_checker = False # used to prevent adding to coords_bad multiple times when multiple regions in a read have bad coordinates
        # checks the subject start and end of the first alignment to determine whether the read is the reverse compliment of what we want
        orientation = ""
        var1_qstart = hits [0][8]
        var1_qend = hits [0][9]
        if var1_qstart < var1_qend:
            orientation = "forward"
        else:
            orientation = "reverse"
        
        
        row_data = {"readID": seq_id}
        for variable in variables: # the code iterates through the variable regions like this so that they get written in the order that they were specified in the blast file
            matching_hits = [hit for hit in hits if hit[1].startswith(variable + "_")] # gets the two hits for the variable region in question
            matching_hits.sort(key=lambda x: int(''.join(filter(str.isdigit, x[1].split("_")[1]))))  # sorts them so that the 3 prime hit comes first
            
            if (len(matching_hits) == 2):
                row_data[variable], status =  get_variable (matching_hits[0], matching_hits[1], seq, orientation)
                if status == "coords_bad" and double_checker == False:
                    coords_bad+=1
                    double_checker = True
            else:
                wrong_num_hits+=1
        
        if not([key for key in variables if key not in row_data or not row_data[key]]): # only append row if variable regions were extracted successfully
            rows.append(row_data)
            good+=1

    else:
        wrong_num_hits +=1

df = pd.DataFrame(rows)
df.to_csv (f"files/{library}.csv", index=False)



# Write the values to the Excel file
total = good + wrong_num_hits + coords_bad
good_percent = 100*(good/total)
wrong_num_hits_percent = 100*(wrong_num_hits/total)
coords_bad_percent = 100*(coords_bad/total)
write_to_excel(summary_file, [library, good, wrong_num_hits, coords_bad, good_percent, wrong_num_hits_percent, coords_bad_percent])

